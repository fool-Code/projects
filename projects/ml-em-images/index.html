<!DOCTYPE html>
<html lang="en-GB">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Georgia', serif;
            line-height: 1.6;
            color: #333;
            background-color: #fafafa;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }

        .back-link {
            display: inline-block;
            margin-bottom: 30px;
            color: #3498db;
            text-decoration: none;
            font-size: 1rem;
            transition: color 0.2s ease;
        }

        .back-link:hover {
            color: #2980b9;
        }

        .back-link::before {
            content: "← ";
        }

        .project-header {
            background: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }

        .project-title {
            font-size: 2.5rem;
            margin-bottom: 15px;
            color: #2c3e50;
        }

        .project-subtitle {
            font-size: 1.2rem;
            color: #666;
            margin-bottom: 25px;
            font-style: italic;
        }

        .project-tech {
            margin-bottom: 20px;
        }

        .tech-tag {
            display: inline-block;
            background: #ecf0f1;
            color: #2c3e50;
            padding: 6px 15px;
            margin: 2px 6px 2px 0;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 500;
        }

        .project-links {
            margin-top: 20px;
        }

        .project-link {
            display: inline-block;
            margin-right: 20px;
            color: #3498db;
            text-decoration: none;
            font-weight: 500;
            padding: 10px 20px;
            border: 2px solid #3498db;
            border-radius: 5px;
            transition: all 0.2s ease;
        }

        .project-link:hover {
            background: #3498db;
            color: white;
        }

        .content-section {
            background: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }

        .section-title {
            font-size: 1.8rem;
            margin-bottom: 20px;
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }

        .image-gallery {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(100px, 1fr));
            gap: 30px;
            margin: 20px 0;
        }

        .project-image {
            width: 100%;
            height: 1300px;
            background: #ecf0f1;
            border-radius: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: #7f8c8d;
            font-size: 1rem;
            border: 2px dashed #bdc3c7;
        }

        .chart-container {
            margin: 20px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
        }

        .features-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .feature-card {
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
            border-left: 4px solid #3498db;
        }

        .feature-title {
            font-size: 1.2rem;
            font-weight: bold;
            margin-bottom: 10px;
            color: #2c3e50;
        }

        .code-snippet {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
        }

        .justify-text {
            text-align: justify;
            text-justify: inter-word;
        }


        @media (max-width: 768px) {
            .container {
                padding: 15px;
            }
            
            .project-header, .content-section {
                padding: 20px;
            }
            
            .project-title {
                font-size: 2rem;
            }
            
            .image-gallery {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="../../index.html" class="back-link">Back to Projects</a>
        
        <header class="project-header">
            <h1 class="project-title">Future Project: Machine Learning applied to Electron Microscopy images</h1>
            <p class="project-subtitle">Future Research Path</p>
            
                <div class="project-tech">
                    <span class="tech-tag">Pytorch</span>
                    <span class="tech-tag">Electron Microscopy</span>
                    <span class="tech-tag">Condensed Matter Physics</span>
                </div>

        </header>

        <section class="content-section">
            <h2 class="section-title">Project Overview</h2>
<p class="justify-text">
For this project, I want to tackle one of the main challenges in electron microscopy imaging: getting good image acquisition and quality. Many things can go wrong during an 
EM session. Poor sample preparation or incorrect storage can cause image drift, making it almost impossible to align parameters such as astigmatism on both axes, cross-over, or field astigmatism. 
Too much or too little beam energy can also create problems, not only for the sample itself but especially for image capture.
</p>
<p class="justify-text" style="margin-top: 10px;">
I've faced these issues myself. Sometimes, when I zoom in on an area of interest, I have to correct field astigmatism, refocus, and even adjust the Z-height to get
 the best possible image. With the arrival of new AI models, there's now a useful way to process images afterwards and enhance a noisy EM picture—though not in a dramatic “CSI-style” way.
</p>
<p class="justify-text" style="margin-top: 10px;">
AI-based post-processing is already common in phones, computer software, and other everyday tools. But in advanced materials characterisation it's only just beginning, 
so there's still plenty to explore.
</p>
        </section>


      <section class="content-section">
    <h2 class="section-title">Small Review of Current Models</h2>
    <p class="justify-text">
        In electron microscopy and other advanced imaging fields, several modern model types are being tested to improve image quality, including diffusion models, vision transformers, 
        and hybrid convolution–transformer networks. Recent studies highlight how diffusion approaches such as <a href="https://www.nature.com/articles/s41467-024-49125-z" target="_blank">EMDiffuse (Chixiang Lu et al., 2024)</a> 
        can enhance ultrastructural EM images and recover very fine detail. Broader surveys of diffusion techniques—like DDPM or DDIM—show they work well for denoising, segmentation, classification, and super-resolution in 
        microscopic images (<a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12309395/" target="_blank">Yan Liu et al., 2025</a>).
    </p>
    <p class="justify-text" style="margin-top: 10px;">
        Transformers and hybrid networks are also gaining ground. For example, a <a href="https://www.nature.com/articles/s41598-024-68918-2" target="_blank">Convolutional Neural Network Transformer (CNNT) (Azaan Rehman et al., 2024)</a> 
        has been developed for denoising fluorescence microscopy images, offering better generalisation and faster adaptation than traditional CNNs. Other research explores 
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253523003597" target="_blank">cross transformers for image denoising (Chunwei Tian et al., 2024)</a>, combining serial, parallel, and residual blocks to clean up images more effectively.
    </p>
    <p class="justify-text" style="margin-top: 10px;">
        Despite this progress, there are still challenges for electron microscopy. 
        Large, well-labelled datasets of clean and noisy images are often hard to obtain, and EM noise patterns, such as drift, astigmatism, or beam damage, are more complex than those found in natural images. 
        Computational cost is another concern, as both transformers and diffusion models can be resource-hungry when dealing with high-resolution data. Finally, models trained on a particular sample type or 
        instrument may not transfer well to others without careful fine-tuning.
    </p>
</section>
            
            <h3 style="margin-top: 25px; margin-bottom: 15px; color: #2c3e50;">Image of recent application</h3>


            <div class="image-gallery">
                <div>
                    <img src="./images/mstad7e41f3_hr.jpg" alt="Denoising SEM images" class="project-image">
                    <div class="image-caption">Denoising results for different methods using SEM images. Reference: <a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253523003597" target="_blank">Applications of deep learning-based denoising
methodologies for scanning electron microscope
images (Seoleun Shin, 2025)</a></div>
                </div>                
            </div>


<section class="content-section">
    <h2 class="section-title">Possible Outcomes</h2>
    <p class="justify-text">
        At the end of this project I hope to get some nice things done.  
        Maybe I can figure out better ways to avoid drift and weird noise when I take EM images, so next time I spend less time fixing settings.  
        I also want to try some of the new image models to clean pictures after the session. If they work, even a little, it means I can save time and still keep small details that normally get lost.  
        It can also show where these models fail with EM data, so I know what to test next or how to make a better dataset.  
    </p>
</section>

    

</div>

</body>
</html>